{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle - LANL Earthquake Prediction\n",
    "\n",
    "General information Forecasting earthquakes is one of the most important problems in Earth science because of their devastating consequences. Current scientific studies related to earthquake forecasting focus on three key points: when the event will occur, where it will occur, and how large it will be. In this competition we try to predict time left to the next laboratory earthquake based on seismic signal data to answer the question of when earthquake will occur.\n",
    "\n",
    "Training data represents one huge signal, but in test data we have many separate chunks, for each of which we need to predict time to failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'sample_submission.csv', 'test', 'train.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "# spectrogram with scipy\n",
    "from scipy import signal\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./data\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "#garbage collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is huge, training data contains nearly 600 million rows and that is A LOT of data to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 5.61 s, total: 1min 13s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# limit the load to 10M lines for display purpose\n",
    "# train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}, nrows=int(10e6)\n",
    "# train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}, nrows=int(50e6))\n",
    "train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "#Collect garbage\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of segments: 4194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0900f6414ca429a836dd15dcd32d414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4194), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = 150_000\n",
    "segments = int(np.floor(train.shape[0] / rows))\n",
    "print(\"number of segments:\",segments)\n",
    "\n",
    "# X = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "#                        columns=features)\n",
    "# Y = pd.DataFrame(index=range(segments), dtype=np.float64,\n",
    "#                        columns=['time_to_failure'])\n",
    "\n",
    "for segment in tqdm(range(segments)):\n",
    "        \n",
    "    seg = train.iloc[segment*rows:segment*rows+rows]\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = seg['time_to_failure'].values\n",
    "    #print(x,y)\n",
    "\n",
    "    fs = 1\n",
    "    # f, t, Sxx = signal.spectrogram(partial_train.values[:,0], fs)\n",
    "    # f, t, Sxx = signal.spectrogram(train.values[:,0], fs)\n",
    "    f, t, Sxx = signal.spectrogram(x, # array_like - Time series of measurement values\n",
    "                               fs = fs, # float, optional - Sampling frequency of the x time series. Defaults to 1.0.\n",
    "                               window = ('tukey', 0.25), # str or tuple or array_like, optional - Desired window to use. If window is a string or tuple, it is passed to get_window to generate the window values, which are DFT-even by default. See get_window for a list of windows and required parameters. If window is array_like it will be used directly as the window and its length must be nperseg. Defaults to a Tukey window with shape parameter of 0.25.\n",
    "                               nperseg = 447, # int, optional - Length of each segment. Defaults to None, but if window is str or tuple, is set to 256, and if window is array_like, is set to the length of the window\n",
    "                               noverlap = 113, # int, optional - Number of points to overlap between segments. If None, noverlap = nperseg // 8. Defaults to None.\n",
    "                               nfft = None, # int, optional - Length of the FFT used, if a zero padded FFT is desired. If None, the FFT length is nperseg. Defaults to None.\n",
    "                               detrend = 'constant', # str or function or False, optional - Specifies how to detrend each segment. If detrend is a string, it is passed as the type argument to the detrend function. If it is a function, it takes a segment and returns a detrended segment. If detrend is False, no detrending is done. Defaults to ‘constant’.\n",
    "                               return_onesided = True, # bool, optional - If True, return a one-sided spectrum for real data. If False return a two-sided spectrum. Note that for complex data, a two-sided spectrum is always returned\n",
    "                               scaling = 'density', # { ‘density’, ‘spectrum’ }, optional - Selects between computing the power spectral density (‘density’) where Sxx has units of V**2/Hz and computing the power spectrum (‘spectrum’) where Sxx has units of V**2, if x is measured in V and fs is measured in Hz. Defaults to ‘density’\n",
    "                               axis = -1, # int, optional - Axis along which the spectrogram is computed; the default is over the last axis (i.e. axis=-1)\n",
    "                               mode = 'psd' # str, optional - Defines what kind of return values are expected. Options are [‘psd’, ‘complex’, ‘magnitude’, ‘angle’, ‘phase’]. ‘complex’ is equivalent to the output of stft with no padding or boundary extension. ‘magnitude’ returns the absolute magnitude of the STFT. ‘angle’ and ‘phase’ return the complex angle of the STFT, with and without unwrapping, respectively\n",
    "                              )\n",
    "    # Returns:\n",
    "    # f : ndarray - Array of sample frequencies.\n",
    "    # t : ndarray - Array of segment times.\n",
    "    # Sxx : ndarray - Spectrogram of x. By default, the last axis of Sxx corresponds to the segment times.\n",
    "\n",
    "    logsxx = np.log(Sxx)\n",
    "    y = y[list(map(int, t))]  # Selects every given resized raw starting from 0\n",
    "    \n",
    "    # print(y)\n",
    "    # break\n",
    "    found = False\n",
    "    index_found = -1\n",
    "    for i in range(len(y)):\n",
    "        if y[i] < 1e-3:\n",
    "            index_found = i\n",
    "            found = True\n",
    "            break\n",
    "        \n",
    "\n",
    "    #if found is False: continue\n",
    "        \n",
    "    # print('x.shape:',x.shape)\n",
    "    # print('y.shape:',y.shape)\n",
    "    # print('t.shape:',t.shape)\n",
    "    # print('f.shape:',f.shape)\n",
    "    # # logsxx_transpose = list(map(list, zip(*logsxx)))\n",
    "    # print('logsxx.shape:',logsxx.shape)\n",
    "    # # print('x',x)\n",
    "    # # print('y raw',y)\n",
    "    # # print(t)\n",
    "    # # print(logsxx_transpose)\n",
    "    \n",
    "    # # print('list(t)',list(map(int, t)))\n",
    "    # print('y.shape filtered',y.shape)\n",
    "    \n",
    "    # print(logsxx)\n",
    "    # https://www.infobyip.com/detectmonitordpi.php\n",
    "    my_dpi = 120\n",
    "    # print('t.shape[0]',t.shape[0])\n",
    "    fig = plt.figure(figsize=(t.shape[0]/my_dpi, f.shape[0]/my_dpi), dpi=my_dpi, frameon=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    plt.yscale('log')\n",
    "\n",
    "    # plt.pcolormesh(t, f, logsxx, norm = colors.LogNorm(vmin=logsxx.min(), vmax=logsxx.max()))\n",
    "    plt.pcolormesh(t, f, logsxx)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylim(0.01, 0.5)\n",
    "    # cbar = plt.colorbar()\n",
    "    # cbar.solids.set_edgecolor(\"face\")\n",
    "    #plt.draw()\n",
    "    plt.savefig('./data/train/seg'+str(segment)+'-x'+str(index_found)+'.png', dpi=my_dpi)\n",
    "    # plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    # figure, axes1 = plt.subplots(figsize=(15,6))\n",
    "\n",
    "    # plt.title(\"Seismic Data Spectrogram for segment \"+str(segment))\n",
    "    # plt.yscale('log')\n",
    "    \n",
    "    # plt.pcolormesh(t, f, logsxx)\n",
    "    # axes1.set_ylabel('Frequency [Hz]')\n",
    "    # plt.xlabel('Time [sec]')\n",
    "    # plt.legend(['Acoustic Data'])\n",
    "    # plt.ylim(0.01, 0.5)\n",
    "    \n",
    "    # axes2 = axes1.twinx()\n",
    "    # plt.plot(t,y, color='r')\n",
    "    # axes2.set_ylabel('Time to Failure', color='r')\n",
    "    # plt.legend(['Time to Failure'])\n",
    "\n",
    "    # plt.savefig('./data/train/plot_seg'+str(segment)+'-x'+str(index_found)+'.png', dpi=my_dpi)\n",
    "    # # plt.show()\n",
    "    \n",
    "    np.savetxt('./data/train/seg'+str(segment)+'.csv', y, delimiter=\",\", fmt='%s')\n",
    "    \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle - LANL Earthquake Prediction - putting all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6901868902339892303\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1613458263000109487\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8606264122534619333\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10551502439\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9567790010695238454\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n",
      "gpu name: /device:GPU:0\n",
      "['train', 'sample_submission.csv', 'test', 'train.csv', 'model', 'train.png', 'sample_submission_bkp.csv', 'test_miny.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "# spectrogram with scipy\n",
    "from scipy import signal\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "import glob, os, sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json, Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, CuDNNGRU, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, TimeDistributed, AveragePooling1D, Embedding, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('gpu name:',tf.test.gpu_device_name())\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output in\n",
    "print(os.listdir(\"./data\"))\n",
    "\n",
    "input_dir = './data/train/'\n",
    "\n",
    "#garbage collect\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to disable the gpu? no\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/shome/perrozzi/.conda/envs/tf_gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to disable the gpu? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "# EXCLUDE GPU (ONLY IF NEEDED!!!!)\n",
    "sess_cpu = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "print('GPU disabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the (huge) training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to load the training data? yes\n",
      "CPU times: user 12 µs, sys: 2 µs, total: 14 µs\n",
      "Wall time: 26 µs\n",
      "training sample size 629145480\n"
     ]
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to load the training data? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "%time\n",
    "# %time\n",
    "# limit the load to 10M lines for display purpose\n",
    "# train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}, nrows=int(10e6)\n",
    "# train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}, nrows=int(50e6))\n",
    "train = pd.read_csv('./data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "#Collect garbage\n",
    "gc.collect()\n",
    "\n",
    "print('training sample size',train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spectrograms for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to create spectrograms for training data? yes\n",
      "number of segments: 125800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f1f9a69e7444769d4ce61cc3496700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to create spectrograms for training data? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "# formula on number of segments from convolutional lectures: (n + 2p - f)/s + 1\n",
    "rows = 150_000\n",
    "stride = 5_000 # <------------- THE MOST IMPORTANT PARAMETER!!!\n",
    "segments = int(np.floor((train.shape[0] - rows)/stride + 1))\n",
    "print(\"number of segments:\",segments)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "for segment in tqdm(range(segments)):\n",
    "    \n",
    "    # if segment>2000: break\n",
    "    \n",
    "    seg_start = segment*stride\n",
    "    seg_end = segment*stride+rows\n",
    "    seg = train.iloc[seg_start:seg_end]\n",
    "    x = seg['acoustic_data'].values\n",
    "    y = seg['time_to_failure'].values\n",
    "    #print(x,y)\n",
    "    \n",
    "    if os.path.isfile('./data/train/seg_start_'+str(seg_start)+'.png'): \n",
    "        # print('skipping file ./data/train/seg_start_'+str(seg_start)+'.png')\n",
    "        continue\n",
    "    \n",
    "\n",
    "    fs = 1\n",
    "    f, t, Sxx = signal.spectrogram(x, # array_like - Time series of measurement values\n",
    "                               fs = fs, # float, optional - Sampling frequency of the x time series. Defaults to 1.0.\n",
    "                               window = ('tukey', 0.25), # str or tuple or array_like, optional - Desired window to use. If window is a string or tuple, it is passed to get_window to generate the window values, which are DFT-even by default. See get_window for a list of windows and required parameters. If window is array_like it will be used directly as the window and its length must be nperseg. Defaults to a Tukey window with shape parameter of 0.25.\n",
    "                               nperseg = 447, # int, optional - Length of each segment. Defaults to None, but if window is str or tuple, is set to 256, and if window is array_like, is set to the length of the window\n",
    "                               noverlap = 113, # int, optional - Number of points to overlap between segments. If None, noverlap = nperseg // 8. Defaults to None.\n",
    "                               nfft = None, # int, optional - Length of the FFT used, if a zero padded FFT is desired. If None, the FFT length is nperseg. Defaults to None.\n",
    "                               detrend = 'constant', # str or function or False, optional - Specifies how to detrend each segment. If detrend is a string, it is passed as the type argument to the detrend function. If it is a function, it takes a segment and returns a detrended segment. If detrend is False, no detrending is done. Defaults to ‘constant’.\n",
    "                               return_onesided = True, # bool, optional - If True, return a one-sided spectrum for real data. If False return a two-sided spectrum. Note that for complex data, a two-sided spectrum is always returned\n",
    "                               scaling = 'density', # { ‘density’, ‘spectrum’ }, optional - Selects between computing the power spectral density (‘density’) where Sxx has units of V**2/Hz and computing the power spectrum (‘spectrum’) where Sxx has units of V**2, if x is measured in V and fs is measured in Hz. Defaults to ‘density’\n",
    "                               axis = -1, # int, optional - Axis along which the spectrogram is computed; the default is over the last axis (i.e. axis=-1)\n",
    "                               mode = 'psd' # str, optional - Defines what kind of return values are expected. Options are [‘psd’, ‘complex’, ‘magnitude’, ‘angle’, ‘phase’]. ‘complex’ is equivalent to the output of stft with no padding or boundary extension. ‘magnitude’ returns the absolute magnitude of the STFT. ‘angle’ and ‘phase’ return the complex angle of the STFT, with and without unwrapping, respectively\n",
    "                              )\n",
    "    # Returns:\n",
    "    # f : ndarray - Array of sample frequencies.\n",
    "    # t : ndarray - Array of segment times.\n",
    "    # Sxx : ndarray - Spectrogram of x. By default, the last axis of Sxx corresponds to the segment times.\n",
    "\n",
    "    #logsxx = np.log(Sxx)\n",
    "    logsxx = Sxx\n",
    "    y = y[list(map(int, t))]  # Selects every given resized raw starting from 0\n",
    "            \n",
    "\n",
    "    # found = False\n",
    "    # index_found = -1\n",
    "    # for i in range(len(y)):\n",
    "    #    if y[i] < 1e-3:\n",
    "    #        index_found = i\n",
    "    #        found = True\n",
    "    #        break\n",
    "    \n",
    "    # if not found: continue\n",
    "    \n",
    "    # print(logsxx.max())\n",
    "    # https://www.infobyip.com/detectmonitordpi.php\n",
    "    my_dpi = 120\n",
    "    # print('t.shape[0]',t.shape[0])\n",
    "    fig = plt.figure(figsize=(t.shape[0]/my_dpi, f.shape[0]/my_dpi), dpi=my_dpi, frameon=False)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    plt.yscale('log')\n",
    "    plt.pcolormesh(t, f, logsxx, norm = colors.LogNorm(vmin=50, vmax=500000))\n",
    "    # plt.pcolormesh(t, f, logsxx)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.ylim(0.01, 0.5)\n",
    "    # cbar = plt.colorbar()\n",
    "    # cbar.solids.set_edgecolor(\"face\")\n",
    "    #plt.draw()\n",
    "    plt.savefig('./data/train/seg_start_'+str(seg_start)+'.png', dpi=my_dpi)\n",
    "    # plt.show()\n",
    "    plt.close(fig)\n",
    "        \n",
    "    np.savetxt('./data/train/seg_start_'+str(seg_start)+'_y.csv', y, delimiter=\",\", fmt='%s')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the features from the Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = input(\"Do you want to retraing VGG16 with spectrogram images? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "base_model = VGG16(weights='imagenet')\n",
    "\n",
    "# last fully connected layer before softmax (4096 parameters)\n",
    "model = keras.models.Model(inputs = base_model.input, outputs = base_model.get_layer('fc2').output)\n",
    "# last convolutional layer (52_584 parameters)\n",
    "# model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "features_train = []\n",
    "y_list = []\n",
    "\n",
    "input_images = glob.glob(input_dir+'/seg*.png')\n",
    "dataset_size = len(input_images)\n",
    "\n",
    "for filename in tqdm(input_images):\n",
    "    # print(filename)\n",
    "    img_path = filename\n",
    "    y_path = img_path.replace('.png','_y.csv')\n",
    "    if len(glob.glob(y_path)) < 1: \n",
    "        print('file',y_path,'not found, skipping')\n",
    "        continue\n",
    "    # print(img_path,y_path)\n",
    "    # sys.exit(0)\n",
    "    y_raw = pd.read_csv(y_path, header = None)#, names=['y'])\n",
    "    #y_resized = y_raw[y_raw.index % 2 != 0]\n",
    "    y_resized = y_raw[::2]\n",
    "    y_resized2 = y_resized.reset_index().T.drop(['index'])\n",
    "\n",
    "    # print(y_raw.info, y_resized.info, y_resized2.info)\n",
    "    #print(y_resized2['y'][1])\n",
    "    #break\n",
    "    #'seg'+str(segment)+'.csv'\n",
    "\n",
    "    # print(img_path)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to Extract the features from the Training data and prepare for fit? yes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42be5af8a14a4dd4bb1889cc72c6e99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file ./data/train/seg_start_504330000_y.csv not found, skipping\n",
      "file ./data/train/seg_start_104790000_y.csv not found, skipping\n",
      "   0     1     2         3         4     5         6     7     8     9     \\\n",
      "0   0.0   0.0   0.0  0.996335  3.123883   0.0  5.507581   0.0   0.0   0.0   \n",
      "1   0.0   0.0   0.0  1.109851  2.174960   0.0  6.384826   0.0   0.0   0.0   \n",
      "2   0.0   0.0   0.0  1.445455  2.489145   0.0  5.879545   0.0   0.0   0.0   \n",
      "3   0.0   0.0   0.0  1.849848  2.256818   0.0  5.715147   0.0   0.0   0.0   \n",
      "4   0.0   0.0   0.0  2.191413  3.639069   0.0  6.401799   0.0   0.0   0.0   \n",
      "\n",
      "   ...      4086      4087      4088  4089      4090      4091  4092  \\\n",
      "0  ...  2.353818  0.000000  1.941416   0.0  3.002819  1.571707   0.0   \n",
      "1  ...  2.476655  0.058558  1.562796   0.0  2.156264  2.160036   0.0   \n",
      "2  ...  2.265565  0.000000  1.580620   0.0  3.634648  2.109096   0.0   \n",
      "3  ...  2.045348  0.000000  0.667124   0.0  2.627021  1.615720   0.0   \n",
      "4  ...  2.378744  0.000000  1.606220   0.0  3.139614  2.047065   0.0   \n",
      "\n",
      "       4093  4094  4095  \n",
      "0  4.714333   0.0   0.0  \n",
      "1  5.032615   0.0   0.0  \n",
      "2  4.269984   0.0   0.0  \n",
      "3  3.465019   0.0   0.0  \n",
      "4  6.530455   0.0   0.0  \n",
      "\n",
      "[5 rows x 4096 columns]\n",
      "         0          1          2          3          4          5    \\\n",
      "0   5.889800   5.889799   5.889799   5.889798   5.889797   5.889796   \n",
      "1   3.007898   3.007897   3.007896   3.007896   3.006899   3.006899   \n",
      "2  11.273697  11.273696  11.273696  11.272600  11.272599  11.272598   \n",
      "3   9.686800   9.686799   9.686798   9.686797   9.686797   9.686796   \n",
      "4   4.350199   4.350199   4.350198   4.350197   4.350196   4.350196   \n",
      "\n",
      "         6          7          8          9    ...        214        215  \\\n",
      "0   5.889796   5.888799   5.888799   5.888798  ...   5.853696   5.852600   \n",
      "1   3.006898   3.006897   3.006896   3.006896  ...   2.970698   2.970698   \n",
      "2  11.272597  11.272597  11.272596  11.271600  ...  11.236498  11.236497   \n",
      "3   9.685800   9.685799   9.685798   9.685797  ...   9.649600   9.649599   \n",
      "4   4.349199   4.349199   4.349198   4.349197  ...   4.313000   4.312999   \n",
      "\n",
      "         216        217        218        219        220        221  \\\n",
      "0   5.852599   5.852598   5.852598   5.852597   5.852596   5.851500   \n",
      "1   2.970697   2.970696   2.969600   2.969599   2.969598   2.969598   \n",
      "2  11.236496  11.235400  11.235399  11.235399  11.235398  11.235397   \n",
      "3   9.649599   9.649598   9.649597   9.649596   9.649596   9.648499   \n",
      "4   4.312998   4.312998   4.312997   4.312996   4.311900   4.311899   \n",
      "\n",
      "         222        223  \n",
      "0   5.851499   5.851498  \n",
      "1   2.969597   2.969596  \n",
      "2  11.235396  11.235396  \n",
      "3   9.648499   9.648498  \n",
      "4   4.311898   4.311898  \n",
      "\n",
      "[5 rows x 224 columns]\n"
     ]
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to Extract the features from the Training data and prepare for fit? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "base_model = VGG16(weights='imagenet')\n",
    "\n",
    "# last fully connected layer before softmax (4096 parameters)\n",
    "model = keras.models.Model(inputs = base_model.input, outputs = base_model.get_layer('fc2').output)\n",
    "# last convolutional layer (52_584 parameters)\n",
    "# model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "features_train = []\n",
    "y_list = []\n",
    "\n",
    "input_images = glob.glob(input_dir+'/seg*.png')\n",
    "dataset_size = len(input_images)\n",
    "\n",
    "for filename in tqdm(input_images):\n",
    "    # print(filename)\n",
    "    img_path = filename\n",
    "    y_path = img_path.replace('.png','_y.csv')\n",
    "    if len(glob.glob(y_path)) < 1: \n",
    "        print('file',y_path,'not found, skipping')\n",
    "        continue\n",
    "    # print(img_path,y_path)\n",
    "    # sys.exit(0)\n",
    "    y_raw = pd.read_csv(y_path, header = None)#, names=['y'])\n",
    "    #y_resized = y_raw[y_raw.index % 2 != 0]\n",
    "    y_resized = y_raw[::2]\n",
    "    y_resized2 = y_resized.reset_index().T.drop(['index'])\n",
    "\n",
    "    # print(y_raw.info, y_resized.info, y_resized2.info)\n",
    "    #print(y_resized2['y'][1])\n",
    "    #break\n",
    "    #'seg'+str(segment)+'.csv'\n",
    "\n",
    "    # print(img_path)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    features_train.append( model.predict(x) )\n",
    "    y_list.append(y_resized2)\n",
    "    # print(features_train.shape)\n",
    "    # print(type(features_train))\n",
    "    # df.append(features_train)\n",
    "\n",
    "# print(len(features_train))\n",
    "\n",
    "df_train = pd.DataFrame(np.concatenate(features_train))\n",
    "print(df_train.head(5))\n",
    "\n",
    "y = pd.DataFrame(np.concatenate(y_list))\n",
    "print(y.head(5))\n",
    "\n",
    "df_train.to_csv(input_dir+'/df_training_features.csv', index=False)\n",
    "y.to_csv(input_dir+'/y.csv', index=False)\n",
    "\n",
    "### recursively write out csv appending it to an existing file\n",
    "# public Boolean AppendToFile(Path fullFilePath, Account obj) {\n",
    "#     logger.info(\" Acquired Write lock on file \" + fullFilePath.getFileName());\n",
    "# \n",
    "#     mapper = new CsvMapper();\n",
    "#     mapper.configure(JsonGenerator.Feature.IGNORE_UNKNOWN, true);\n",
    "#     schema = mapper.schemaFor(Account.class).withColumnSeparator('|');\n",
    "# \n",
    "#         File outputFile = new File(fullFilePath.toUri());\n",
    "#         if (!outputFile.exists()) {\n",
    "#             outputFile.createNewFile();\n",
    "#         }\n",
    "#         ObjectWriter writer = mapper.writer(schema);\n",
    "#         OutputStream outstream = new FileOutputStream(outputFile , true);\n",
    "#         writer.writeValue(outstream,obj);\n",
    "#  return true;\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to load the extracted features from the Training data and split it into training/validation? yes\n",
      "[ 5.85149836  2.96959616 11.23539558 ...  3.42059923  0.21399968\n",
      "  1.09679996]\n",
      "X_train.shape (113218, 4096, 1) X_test.shape (12580, 4096, 1) y_train.shape (113218,) y_test.shape (12580,)\n"
     ]
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to load the extracted features from the Training data and split it into training/validation? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "df_train2 = pd.read_csv(input_dir+'/df_training_features.csv').values\n",
    "# df_train2 = df_train2.reshape((df_train2.shape[0], df_train2.shape[1], 1))\n",
    "\n",
    "# y2 = pd.read_csv(input_dir+'/y.csv').values\n",
    "#print(y2[0][1])\n",
    "# y2 = y2.min(axis=1)\n",
    "# only the last time from failure value is relevant!\n",
    "y2 = pd.read_csv(input_dir+'/y.csv')['223'].values\n",
    "# y2 = y2.reshape((y2.shape[0], y2.shape[1], 1))\n",
    "# df_train.drop(['Unnamed: 0'])\n",
    "print(y2)\n",
    "# print(y2.mean(axis=1))\n",
    "np.savetxt('./data/test_miny.csv', y2, delimiter=\",\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train2, y2, test_size=0.1, random_state=42)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print('X_train.shape',X_train.shape, 'X_test.shape',X_test.shape, 'y_train.shape',y_train.shape, 'y_test.shape',y_test.shape)\n",
    "#print(X_train.head(5))\n",
    "#print(y_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.acc, label=\"accuracy\")\n",
    "        ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "        \n",
    "plot_learning_loss = PlotLearning()\n",
    "\n",
    "# updatable plot\n",
    "# a minimal example (sort of)\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113218/113218 [==============================] - 833s 7ms/step - loss: 2.3205 - acc: 0.0000e+00 - val_loss: 2.2556 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      " 45760/113218 [===========>..................] - ETA: 7:49 - loss: 2.2928 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dda2f903eea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                         )\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to build and fit the model? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "print('gpu name:',tf.test.gpu_device_name())\n",
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(CuDNNGRU(100, input_shape=(4096,1), \n",
    "                        # regularizers.l1_l2(l1=0.01, l2=0.01), \n",
    "                        return_sequences=True))\n",
    "model_lstm.add(CuDNNGRU(100,return_sequences=True))\n",
    "model_lstm.add(CuDNNGRU(100))\n",
    "# model_lstm.add(Dense(50, activation='relu'))\n",
    "# model_lstm.add(Dense(50, activation='relu'))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(10, activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_lstm.summary()\n",
    "\n",
    "# Compile and fit model\n",
    "model_lstm.compile(optimizer=Adam(lr=0.0005), loss=\"mae\", \n",
    "                  # metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model_lstm.to_json()\n",
    "with open(\"./data/model/model-CuDNNGRU.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# checkpoint\n",
    "# filepath=\"./data/train/weights3-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "filepath=\"./data/model/weights-CuDNNGRU-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             # monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True\n",
    "                             #, mode='max'\n",
    "                            )\n",
    "callbacks_list = [checkpoint,\n",
    "                 # plot_learning_loss,\n",
    "                 plot_losses\n",
    "                 ]\n",
    "# Fit the model\n",
    "\n",
    "history = model_lstm.fit( \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            epochs = 50, \n",
    "                            validation_data = (X_test, y_test),\n",
    "                            batch_size = 64,\n",
    "                            callbacks=callbacks_list\n",
    "                        )\n",
    "\n",
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # return None\n",
    "\n",
    "perf_plot(history)\n",
    "\n",
    "plt.savefig('./data/train.png')\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model_lstm.save_weights(\"./data/model/model-CuDNNGRU_final_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to continue fitting with the loaded model and weights? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "history = model_lstm.fit( \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            epochs = 50, \n",
    "                            validation_data = (X_test, y_test),\n",
    "                            batch_size = 64,\n",
    "                            callbacks=callbacks_list\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to load a saved model and weights? yes\n",
      "gpu name: /device:GPU:0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru (CuDNNGRU)         (None, 4096, 100)         30900     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 4096, 100)         60600     \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 100)               60600     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 153,121\n",
      "Trainable params: 153,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16773 samples, validate on 4194 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Fail to find the dnn implementation.\n\t [[{{node cu_dnngru/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/cu_dnngru/CudnnRNN_grad/CudnnRNNBackprop\"], direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cu_dnngru/transpose, cu_dnngru/ExpandDims, training/Adam/Const_27, cu_dnngru/concat)]]\n\t [[{{node loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_3/_221}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_664_l...t/Switch_3\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c854c39f3392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                             \u001b[0;31m# batch_size = 256,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                         )\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: Fail to find the dnn implementation.\n\t [[{{node cu_dnngru/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, _class=[\"loc:@training/Adam/gradients/cu_dnngru/CudnnRNN_grad/CudnnRNNBackprop\"], direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=0, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cu_dnngru/transpose, cu_dnngru/ExpandDims, training/Adam/Const_27, cu_dnngru/concat)]]\n\t [[{{node loss/dense_1_loss/broadcast_weights/assert_broadcastable/AssertGuard/Assert/Switch_3/_221}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_664_l...t/Switch_3\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SAFETY GUARD TO PREVENT FROM RUNNING BY MISTAKE\n",
    "answer = input(\"Do you want to load a saved model and weights? \")\n",
    "if answer != 'yes': sys.exit(0)\n",
    "\n",
    "print('gpu name:',tf.test.gpu_device_name())\n",
    "\n",
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(CuDNNGRU(100, input_shape=(4096,1), \n",
    "                        # regularizers.l1_l2(l1=0.01, l2=0.01), \n",
    "                        return_sequences=True))\n",
    "model_lstm.add(CuDNNGRU(100,return_sequences=True))\n",
    "model_lstm.add(CuDNNGRU(100))\n",
    "# model_lstm.add(Dense(50, activation='relu'))\n",
    "# model_lstm.add(Dense(50, activation='relu'))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(10, activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='linear'))\n",
    "\n",
    "model_lstm.summary()\n",
    "\n",
    "# Compile and fit model\n",
    "model_lstm.compile(optimizer=Adam(lr=0.0005), loss=\"mae\", \n",
    "                  # metrics=['accuracy']\n",
    "                  )\n",
    "\n",
    "model_lstm.load_weights('./data/model/weights-CuDNNGRU-improvement-16.hdf5')\n",
    "\n",
    "# checkpoint\n",
    "# filepath=\"./data/train/weights3-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "filepath=\"./data/model/weights_reloaded-CuDNNGRU-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             # monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True\n",
    "                             #, mode='max'\n",
    "                            )\n",
    "callbacks_list = [checkpoint,\n",
    "                  # plot_learning_loss,\n",
    "                  plot_losses\n",
    "                 ]\n",
    "# Fit the model\n",
    "\n",
    "history = model_lstm.fit( \n",
    "                            X_train, \n",
    "                            y_train, \n",
    "                            epochs = 2, \n",
    "                            validation_data = (X_test, y_test),\n",
    "                            batch_size = 64,\n",
    "                            # batch_size = 256,\n",
    "                            callbacks=callbacks_list\n",
    "                        )\n",
    "\n",
    "def perf_plot(history, what = 'loss'):\n",
    "    x = history.history[what]\n",
    "    val_x = history.history['val_' + what]\n",
    "    epochs = np.asarray(history.epoch) + 1\n",
    "    \n",
    "    plt.plot(epochs, x, 'bo', label = \"Training \" + what)\n",
    "    plt.plot(epochs, val_x, 'b', label = \"Validation \" + what)\n",
    "    plt.title(\"Training and validation \" + what)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # return None\n",
    "\n",
    "perf_plot(history)\n",
    "\n",
    "plt.savefig('./data/train.png')\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model_lstm.to_json()\n",
    "with open(\"./data/model/model_reloaded-CuDNNGRU.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_lstm.save_weights(\"./data/model/model_reloaded-CuDNNGRU_final_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "Y_test_hat = model_lstm.predict(X_train)\n",
    "\n",
    "Y_test_hat = np.reshape(Y_test_hat, (1,np.product(Y_test_hat.shape)))\n",
    "\n",
    "residuals = np.subtract(Y_test_hat,y_train)\n",
    "\n",
    "print(Y_test_hat.shape, residuals.shape, y_train.shape)\n",
    "\n",
    "figure, axes1 = plt.subplots(figsize=(18,10))\n",
    "\n",
    "plt.scatter(y_train, residuals)\n",
    "plt.xlabel(\"y_train\")\n",
    "plt.ylabel(\"Y_test_hat residuals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "Y_test_hat = model_lstm.predict(X_train)\n",
    "y_test1 = np.reshape(y_train, (np.product(y_train.shape)))\n",
    "\n",
    "Y_test_hat = np.reshape(Y_test_hat, (np.product(Y_test_hat.shape)))\n",
    "residuals = np.subtract(Y_test_hat,y_test1)\n",
    "\n",
    "print(Y_test_hat.shape, residuals.shape, y_test.shape)\n",
    "figure, axes1 = plt.subplots(figsize=(18,10))\n",
    "plt.hist2d(y_test1, residuals,100)\n",
    "plt.xlabel(\"y_train\")\n",
    "plt.ylabel(\"Y_test_hat residuals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
